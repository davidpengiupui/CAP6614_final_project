{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb56efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guangyu/anaconda3/envs/test/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import os.path as osp\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random, pdb, math, copy\n",
    "#from .autonotebook import tqdm as notebook_tqdm\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd20c3f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d04da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='SHOT')\n",
    "parser.add_argument('--gpu_id', type=str, nargs='?', default='3', help=\"device id to run\")\n",
    "parser.add_argument('--s', type=int, default=2, help=\"source\")\n",
    "parser.add_argument('--t', type=int, default=0, help=\"target\")\n",
    "parser.add_argument('--max_epoch', type=int, default=100, help=\"max iterations\")\n",
    "parser.add_argument('--batch_size', type=int, default=64, help=\"batch_size\")\n",
    "parser.add_argument('--worker', type=int, default=4, help=\"number of workers\")\n",
    "parser.add_argument('--dset', type=str, default='office', choices=['VISDA-C', 'office', 'office-home', 'office-caltech'])\n",
    "parser.add_argument('--lr', type=float, default=1e-2, help=\"learning rate\")\n",
    "parser.add_argument('--net', type=str, default='resnet50', help=\"vgg16, resnet50, resnet101\")\n",
    "parser.add_argument('--seed', type=int, default=2020, help=\"random seed\")\n",
    "parser.add_argument('--bottleneck', type=int, default=256)\n",
    "parser.add_argument('--epsilon', type=float, default=1e-5)\n",
    "parser.add_argument('--layer', type=str, default=\"wn\", choices=[\"linear\", \"wn\"])\n",
    "parser.add_argument('--classifier', type=str, default=\"bn\", choices=[\"ori\", \"bn\"])\n",
    "parser.add_argument('--smooth', type=float, default=0.1)   \n",
    "parser.add_argument('--output', type=str, default='san')\n",
    "parser.add_argument('--da', type=str, default='uda', choices=['uda', 'pda', 'oda'])\n",
    "parser.add_argument('--trte', type=str, default='val', choices=['full', 'val'])\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76243362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called with args:\n",
      "Namespace(gpu_id='3', s=2, t=0, max_epoch=100, batch_size=64, worker=4, dset='office', lr=0.01, net='resnet50', seed=2020, bottleneck=256, epsilon=1e-05, layer='wn', classifier='bn', smooth=0.1, output='san', da='uda', trte='val')\n"
     ]
    }
   ],
   "source": [
    "print('Called with args:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e89e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dset == 'office-home':\n",
    "    names = ['Art', 'Clipart', 'Product', 'Real_World']\n",
    "    args.class_num = 65 \n",
    "if args.dset == 'office':\n",
    "    names = ['amazon', 'dslr', 'webcam']\n",
    "    args.class_num = 31\n",
    "if args.dset == 'VISDA-C':\n",
    "    names = ['train', 'validation']\n",
    "    args.class_num = 12\n",
    "if args.dset == 'office-caltech':\n",
    "    names = ['amazon', 'caltech', 'dslr', 'webcam']\n",
    "    args.class_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022518e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "SEED = args.seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c517748",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/'\n",
    "args.s_dset_path = folder + args.dset + '/' + names[args.s] + '_list.txt'\n",
    "args.test_dset_path = folder + args.dset + '/' + names[args.t] + '_list.txt'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9668e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/office/webcam_list.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.s_dset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885a9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dset == 'office-home':\n",
    "    if args.da == 'pda':\n",
    "        args.class_num = 65\n",
    "        args.src_classes = [i for i in range(65)]\n",
    "        args.tar_classes = [i for i in range(25)]\n",
    "    if args.da == 'oda':\n",
    "        args.class_num = 25\n",
    "        args.src_classes = [i for i in range(25)]\n",
    "        args.tar_classes = [i for i in range(65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1ee6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.output_dir_src = osp.join(args.output, args.da, args.dset, names[args.s][0].upper())\n",
    "args.name_src = names[args.s][0].upper()\n",
    "if not osp.exists(args.output_dir_src):\n",
    "    os.system('mkdir -p ' + args.output_dir_src)\n",
    "if not osp.exists(args.output_dir_src):\n",
    "    os.mkdir(args.output_dir_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0a4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_args(args):\n",
    "    s = \"==========================================\\n\"\n",
    "    for arg, content in args.__dict__.items():\n",
    "        s += \"{}:{}\\n\".format(arg, content)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.out_file = open(osp.join(args.output_dir_src, 'log.txt'), 'w')\n",
    "args.out_file.write(print_args(args)+'\\n')\n",
    "args.out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb8b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.out_file = open(osp.join(args.output_dir_src, 'log_test.txt'), 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e163824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called with args:\n",
      "Namespace(gpu_id='3', s=2, t=0, max_epoch=100, batch_size=64, worker=4, dset='office', lr=0.01, net='resnet50', seed=2020, bottleneck=256, epsilon=1e-05, layer='wn', classifier='bn', smooth=0.1, output='san', da='uda', trte='val', class_num=31, s_dset_path='./data/office/webcam_list.txt', test_dset_path='./data/office/amazon_list.txt', output_dir_src='san/uda/office/W', name_src='W', out_file=<_io.TextIOWrapper name='san/uda/office/W/log_test.txt' mode='w' encoding='UTF-8'>)\n"
     ]
    }
   ],
   "source": [
    "print('Called with args:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a253204",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164fe6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2b3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(image_list, labels):\n",
    "    if labels:\n",
    "        len_ = len(image_list)\n",
    "        images = [(image_list[i].strip(), labels[i, :]) for i in range(len_)]\n",
    "    else:\n",
    "        if len(image_list[0].split()) > 2:\n",
    "            images = [(val.split()[0], np.array([int(la) for la in val.split()[1:]])) for val in image_list]\n",
    "        else:\n",
    "            images = [(val.split()[0], int(val.split()[1])) for val in image_list]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61bf0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "def l_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63a9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageList(Dataset):\n",
    "    def __init__(self, image_list, labels=None, transform=None, target_transform=None, mode='RGB'):\n",
    "        imgs = make_dataset(image_list, labels)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        if mode == 'RGB':\n",
    "            self.loader = rgb_loader\n",
    "        elif mode == 'L':\n",
    "            self.loader = l_loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09932a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(args): \n",
    "    ## prepare data\n",
    "    dsets = {}\n",
    "    dset_loaders = {}\n",
    "    train_bs = args.batch_size\n",
    "    txt_src = open(args.s_dset_path).readlines()\n",
    "    txt_test = open(args.test_dset_path).readlines()\n",
    "\n",
    "    if not args.da == 'uda':\n",
    "        label_map_s = {}\n",
    "        for i in range(len(args.src_classes)):\n",
    "            label_map_s[args.src_classes[i]] = i\n",
    "        \n",
    "        new_src = []\n",
    "        for i in range(len(txt_src)):\n",
    "            rec = txt_src[i]\n",
    "            reci = rec.strip().split(' ')\n",
    "            if int(reci[1]) in args.src_classes:\n",
    "                line = reci[0] + ' ' + str(label_map_s[int(reci[1])]) + '\\n'   \n",
    "                new_src.append(line)\n",
    "        txt_src = new_src.copy()\n",
    "\n",
    "        new_tar = []\n",
    "        for i in range(len(txt_test)):\n",
    "            rec = txt_test[i]\n",
    "            reci = rec.strip().split(' ')\n",
    "            if int(reci[1]) in args.tar_classes:\n",
    "                if int(reci[1]) in args.src_classes:\n",
    "                    line = reci[0] + ' ' + str(label_map_s[int(reci[1])]) + '\\n'   \n",
    "                    new_tar.append(line)\n",
    "                else:\n",
    "                    line = reci[0] + ' ' + str(len(label_map_s)) + '\\n'   \n",
    "                    new_tar.append(line)\n",
    "        txt_test = new_tar.copy()\n",
    "\n",
    "    if args.trte == \"val\":\n",
    "        dsize = len(txt_src)\n",
    "        tr_size = int(0.9*dsize)\n",
    "        # print(dsize, tr_size, dsize - tr_size)\n",
    "        tr_txt, te_txt = torch.utils.data.random_split(txt_src, [tr_size, dsize - tr_size])\n",
    "    else:\n",
    "        dsize = len(txt_src)\n",
    "        tr_size = int(0.9*dsize)\n",
    "        _, te_txt = torch.utils.data.random_split(txt_src, [tr_size, dsize - tr_size])\n",
    "        tr_txt = txt_src\n",
    "\n",
    "    dsets[\"source_tr\"] = ImageList(tr_txt, transform=image_train())\n",
    "    dset_loaders[\"source_tr\"] = DataLoader(dsets[\"source_tr\"], batch_size=train_bs, shuffle=True, num_workers=args.worker, drop_last=False)\n",
    "    dsets[\"source_te\"] = ImageList(te_txt, transform=image_test())\n",
    "    dset_loaders[\"source_te\"] = DataLoader(dsets[\"source_te\"], batch_size=train_bs, shuffle=True, num_workers=args.worker, drop_last=False)\n",
    "    dsets[\"test\"] = ImageList(txt_test, transform=image_test())\n",
    "    dset_loaders[\"test\"] = DataLoader(dsets[\"test\"], batch_size=train_bs*2, shuffle=True, num_workers=args.worker, drop_last=False)\n",
    "\n",
    "    return dset_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81c5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_train(resize_size=256, crop_size=224, alexnet=False):\n",
    "    if not alexnet:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    else:\n",
    "        normalize = Normalize(meanfile='./ilsvrc_2012_mean.npy')\n",
    "    \n",
    "    return  transforms.Compose([\n",
    "        transforms.Resize((resize_size, resize_size)),\n",
    "        transforms.RandomCrop(crop_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26cedb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_test(resize_size=256, crop_size=224, alexnet=False):\n",
    "    if not alexnet:\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225])\n",
    "    else:\n",
    "        normalize = Normalize(meanfile='./ilsvrc_2012_mean.npy')\n",
    "    \n",
    "    return  transforms.Compose([\n",
    "        transforms.Resize((resize_size, resize_size)),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e55786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_loaders = data_load(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65a765",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a91ad3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.nn.utils.weight_norm as weightNorm\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8473b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coeff(iter_num, high=1.0, low=0.0, alpha=10.0, max_iter=10000.0):\n",
    "    return np.float(2.0 * (high - low) / (1.0 + np.exp(-alpha*iter_num / max_iter)) - (high - low) + low)\n",
    "\n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1 or classname.find('ConvTranspose2d') != -1:\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc286b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {\"resnet18\":models.resnet18, \"resnet34\":models.resnet34, \"resnet50\":models.resnet50, \n",
    "\"resnet101\":models.resnet101, \"resnet152\":models.resnet152, \"resnext50\":models.resnext50_32x4d, \"resnext101\":models.resnext101_32x8d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9db6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBase(nn.Module):\n",
    "    def __init__(self, res_name):\n",
    "        super(ResBase, self).__init__()\n",
    "        model_resnet = res_dict[res_name](pretrained=True)\n",
    "        self.conv1 = model_resnet.conv1\n",
    "        self.bn1 = model_resnet.bn1\n",
    "        self.relu = model_resnet.relu\n",
    "        self.maxpool = model_resnet.maxpool\n",
    "        self.layer1 = model_resnet.layer1\n",
    "        self.layer2 = model_resnet.layer2\n",
    "        self.layer3 = model_resnet.layer3\n",
    "        self.layer4 = model_resnet.layer4\n",
    "        self.avgpool = model_resnet.avgpool\n",
    "        self.in_features = model_resnet.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "586d6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feat_bootleneck(nn.Module):\n",
    "    def __init__(self, feature_dim, bottleneck_dim=256, type=\"ori\"):\n",
    "        super(feat_bootleneck, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(bottleneck_dim, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.bottleneck = nn.Linear(feature_dim, bottleneck_dim)\n",
    "        self.bottleneck.apply(init_weights)\n",
    "        self.type = type\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bottleneck(x)\n",
    "        if self.type == \"bn\":\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "169436ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feat_classifier(nn.Module):\n",
    "    def __init__(self, class_num, bottleneck_dim=256, type=\"linear\"):\n",
    "        super(feat_classifier, self).__init__()\n",
    "        self.type = type\n",
    "        if type == 'wn':\n",
    "            self.fc = weightNorm(nn.Linear(bottleneck_dim, class_num), name=\"weight\")\n",
    "            self.fc.apply(init_weights)\n",
    "        else:\n",
    "            self.fc = nn.Linear(bottleneck_dim, class_num)\n",
    "            self.fc.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e342e",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "239e35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c27277df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "    \"\"\"Cross entropy loss with label smoothing regularizer.\n",
    "    Reference:\n",
    "    Szegedy et al. Rethinking the Inception Architecture for Computer Vision. CVPR 2016.\n",
    "    Equation: y = (1 - epsilon) * y + epsilon / K.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        epsilon (float): weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, epsilon=0.1, use_gpu=True, reduction=True):\n",
    "        super(CrossEntropyLabelSmooth, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.use_gpu = use_gpu\n",
    "        self.reduction = reduction\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: prediction matrix (before softmax) with shape (batch_size, num_classes)\n",
    "            targets: ground truth labels with shape (num_classes)\n",
    "        \"\"\"\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "        targets = torch.zeros(log_probs.size()).scatter_(1, targets.unsqueeze(1).cpu(), 1)\n",
    "        if self.use_gpu: targets = targets.cuda()\n",
    "        targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "        loss = (- targets * log_probs).sum(dim=1)\n",
    "        if self.reduction:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f187762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(input_):\n",
    "    bs = input_.size(0)\n",
    "    epsilon = 1e-5\n",
    "    entropy = -input_ * torch.log(input_ + epsilon)\n",
    "    entropy = torch.sum(entropy, dim=1)\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42add300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_copy(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr0'] = param_group['lr']\n",
    "    return optimizer\n",
    "\n",
    "def lr_scheduler(optimizer, iter_num, max_iter, gamma=10, power=0.75):\n",
    "    decay = (1 + gamma * iter_num / max_iter) ** (-power)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr0'] * decay\n",
    "        param_group['weight_decay'] = 1e-3\n",
    "        param_group['momentum'] = 0.9\n",
    "        param_group['nesterov'] = True\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3a728",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c80987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(loader, netF, netB, netC, flag=False):\n",
    "    start_test = True\n",
    "    with torch.no_grad():\n",
    "        iter_test = iter(loader)\n",
    "        for i in range(len(loader)):\n",
    "            data = iter_test.next()\n",
    "            inputs = data[0]\n",
    "            labels = data[1]\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = netC(netB(netF(inputs)))\n",
    "            if start_test:\n",
    "                all_output = outputs.float().cpu()\n",
    "                all_label = labels.float().cpu()\n",
    "                start_test = False\n",
    "            else:\n",
    "                all_output = torch.cat((all_output, outputs.float().cpu()), 0)\n",
    "                all_label = torch.cat((all_label, labels.float().cpu()), 0)\n",
    "\n",
    "    all_output = nn.Softmax(dim=1)(all_output)\n",
    "    _, predict = torch.max(all_output, 1)\n",
    "    accuracy = torch.sum(torch.squeeze(predict).float() == all_label).item() / float(all_label.size()[0])\n",
    "    mean_ent = torch.mean(Entropy(all_output)).data.item()\n",
    "   \n",
    "    if flag:\n",
    "        matrix = confusion_matrix(all_label, torch.squeeze(predict).float())\n",
    "        acc = matrix.diagonal()/matrix.sum(axis=1) * 100\n",
    "        aacc = acc.mean()\n",
    "        aa = [str(np.round(i, 2)) for i in acc]\n",
    "        acc = ' '.join(aa)\n",
    "        return aacc, acc\n",
    "    else:\n",
    "        return accuracy*100, mean_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ae46fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_source(args):\n",
    "    dset_loaders = data_load(args)\n",
    "    ## set base network\n",
    "    if args.net[0:3] == 'res':\n",
    "        netF = ResBase(res_name=args.net).cuda()\n",
    "    elif args.net[0:3] == 'vgg':\n",
    "        netF = VGGBase(vgg_name=args.net).cuda()  \n",
    "\n",
    "    netB = feat_bootleneck(type=args.classifier, feature_dim=netF.in_features, bottleneck_dim=args.bottleneck).cuda()\n",
    "    netC = feat_classifier(type=args.layer, class_num = args.class_num, bottleneck_dim=args.bottleneck).cuda()\n",
    "\n",
    "    param_group = []\n",
    "    learning_rate = args.lr\n",
    "    for k, v in netF.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate*0.1}]\n",
    "    for k, v in netB.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]\n",
    "    for k, v in netC.named_parameters():\n",
    "        param_group += [{'params': v, 'lr': learning_rate}]   \n",
    "    optimizer = optim.SGD(param_group)\n",
    "    optimizer = op_copy(optimizer)\n",
    "\n",
    "    acc_init = 0\n",
    "    max_iter = args.max_epoch * len(dset_loaders[\"source_tr\"])\n",
    "    interval_iter = max_iter // 20\n",
    "    iter_num = 0\n",
    "\n",
    "    netF.train()\n",
    "    netB.train()\n",
    "    netC.train()\n",
    "\n",
    "    while iter_num < max_iter:\n",
    "        try:\n",
    "            inputs_source, labels_source = iter_source.next()\n",
    "        except:\n",
    "            iter_source = iter(dset_loaders[\"source_tr\"])\n",
    "            inputs_source, labels_source = iter_source.next()\n",
    "\n",
    "        if inputs_source.size(0) == 1:\n",
    "            continue\n",
    "\n",
    "        iter_num += 1\n",
    "        lr_scheduler(optimizer, iter_num=iter_num, max_iter=max_iter)\n",
    "\n",
    "        inputs_source, labels_source = inputs_source.cuda(), labels_source.cuda()\n",
    "        outputs_source = netC(netB(netF(inputs_source)))\n",
    "        classifier_loss = CrossEntropyLabelSmooth(num_classes=args.class_num, epsilon=args.smooth)(outputs_source, labels_source)            \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        classifier_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter_num % interval_iter == 0 or iter_num == max_iter:\n",
    "            netF.eval()\n",
    "            netB.eval()\n",
    "            netC.eval()\n",
    "            if args.dset=='VISDA-C':\n",
    "                acc_s_te, acc_list = cal_acc(dset_loaders['source_te'], netF, netB, netC, True)\n",
    "                log_str = 'Task: {}, Iter:{}/{}; Accuracy = {:.2f}%'.format(args.name_src, iter_num, max_iter, acc_s_te) + '\\n' + acc_list\n",
    "            else:\n",
    "                acc_s_te, _ = cal_acc(dset_loaders['source_te'], netF, netB, netC, False)\n",
    "                log_str = 'Task: {}, Iter:{}/{}; Accuracy = {:.2f}%'.format(args.name_src, iter_num, max_iter, acc_s_te)\n",
    "            args.out_file.write(log_str + '\\n')\n",
    "            args.out_file.flush()\n",
    "            print(log_str+'\\n')\n",
    "\n",
    "            if acc_s_te >= acc_init:\n",
    "                acc_init = acc_s_te\n",
    "                best_netF = netF.state_dict()\n",
    "                best_netB = netB.state_dict()\n",
    "                best_netC = netC.state_dict()\n",
    "\n",
    "            netF.train()\n",
    "            netB.train()\n",
    "            netC.train()\n",
    "                \n",
    "    torch.save(best_netF, osp.join(args.output_dir_src, \"source_F_test.pt\"))\n",
    "    torch.save(best_netB, osp.join(args.output_dir_src, \"source_B_test.pt\"))\n",
    "    torch.save(best_netC, osp.join(args.output_dir_src, \"source_C_test.pt\"))\n",
    "\n",
    "    return netF, netB, netC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52d67969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_target(args):\n",
    "    dset_loaders = data_load(args)\n",
    "    ## set base network\n",
    "    if args.net[0:3] == 'res':\n",
    "        netF = ResBase(res_name=args.net).cuda()\n",
    "    elif args.net[0:3] == 'vgg':\n",
    "        netF = VGGBase(vgg_name=args.net).cuda()  \n",
    "\n",
    "    netB = feat_bootleneck(type=args.classifier, feature_dim=netF.in_features, bottleneck_dim=args.bottleneck).cuda()\n",
    "    netC = feat_classifier(type=args.layer, class_num = args.class_num, bottleneck_dim=args.bottleneck).cuda()\n",
    "    \n",
    "    args.modelpath = args.output_dir_src + '/source_F_test.pt'   \n",
    "    netF.load_state_dict(torch.load(args.modelpath))\n",
    "    args.modelpath = args.output_dir_src + '/source_B_test.pt'   \n",
    "    netB.load_state_dict(torch.load(args.modelpath))\n",
    "    args.modelpath = args.output_dir_src + '/source_C_test.pt'   \n",
    "    netC.load_state_dict(torch.load(args.modelpath))\n",
    "    netF.eval()\n",
    "    netB.eval()\n",
    "    netC.eval()\n",
    "\n",
    "    if args.da == 'oda':\n",
    "        acc_os1, acc_os2, acc_unknown = cal_acc_oda(dset_loaders['test'], netF, netB, netC)\n",
    "        log_str = '\\nTraining: {}, Task: {}, Accuracy = {:.2f}% / {:.2f}% / {:.2f}%'.format(args.trte, args.name, acc_os2, acc_os1, acc_unknown)\n",
    "    else:\n",
    "        if args.dset=='VISDA-C':\n",
    "            acc, acc_list = cal_acc(dset_loaders['test'], netF, netB, netC, True)\n",
    "            log_str = '\\nTraining: {}, Task: {}, Accuracy = {:.2f}%'.format(args.trte, args.name, acc) + '\\n' + acc_list\n",
    "        else:\n",
    "            acc, _ = cal_acc(dset_loaders['test'], netF, netB, netC, False)\n",
    "            log_str = '\\nTraining: {}, Task: {}, Accuracy = {:.2f}%'.format(args.trte, args.name, acc)\n",
    "\n",
    "    args.out_file.write(log_str)\n",
    "    args.out_file.flush()\n",
    "    print(log_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d5c6f",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55847b",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d6e8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/'\n",
    "args.s_dset_path = folder + args.dset + '/' + names[args.s] + '_list.txt'\n",
    "args.test_dset_path = folder + args.dset + '/' + names[args.t] + '_list.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "841a2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dset == 'office-home':\n",
    "    if args.da == 'pda':\n",
    "        args.class_num = 65\n",
    "        args.src_classes = [i for i in range(65)]\n",
    "        args.tar_classes = [i for i in range(25)]\n",
    "    if args.da == 'oda':\n",
    "        args.class_num = 25\n",
    "        args.src_classes = [i for i in range(25)]\n",
    "        args.tar_classes = [i for i in range(65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b23853d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.output_dir_src = osp.join(args.output, args.da, args.dset, names[args.s][0].upper())\n",
    "args.name_src = names[args.s][0].upper()\n",
    "if not osp.exists(args.output_dir_src):\n",
    "    os.system('mkdir -p ' + args.output_dir_src)\n",
    "if not osp.exists(args.output_dir_src):\n",
    "    os.mkdir(args.output_dir_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6018d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.out_file = open(osp.join(args.output_dir_src, 'log.txt'), 'w')\n",
    "args.out_file.write(print_args(args)+'\\n')\n",
    "args.out_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd85d942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in range(4):\n",
    "    #args.s = i\n",
    "    #print('For Source ',names[args.s])\n",
    "    #train_source(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd1dd020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guangyu/anaconda3/envs/test/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/guangyu/anaconda3/envs/test/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: W, Iter:60/1200; Accuracy = 98.75%\n",
      "\n",
      "Task: W, Iter:120/1200; Accuracy = 97.50%\n",
      "\n",
      "Task: W, Iter:180/1200; Accuracy = 97.50%\n",
      "\n",
      "Task: W, Iter:240/1200; Accuracy = 98.75%\n",
      "\n",
      "Task: W, Iter:300/1200; Accuracy = 98.75%\n",
      "\n",
      "Task: W, Iter:360/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:420/1200; Accuracy = 98.75%\n",
      "\n",
      "Task: W, Iter:480/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:540/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:600/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:660/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:720/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:780/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:840/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:900/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:960/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:1020/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:1080/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:1140/1200; Accuracy = 100.00%\n",
      "\n",
      "Task: W, Iter:1200/1200; Accuracy = 100.00%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ResBase(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (3): Bottleneck(\n",
       "       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (3): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (4): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (5): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): Bottleneck(\n",
       "       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): Bottleneck(\n",
       "       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (2): Bottleneck(\n",
       "       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       " ),\n",
       " feat_bootleneck(\n",
       "   (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (dropout): Dropout(p=0.5, inplace=False)\n",
       "   (bottleneck): Linear(in_features=2048, out_features=256, bias=True)\n",
       " ),\n",
       " feat_classifier(\n",
       "   (fc): Linear(in_features=256, out_features=31, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c78aa",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60c717b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.out_file = open(osp.join(args.output_dir_src, 'log_test.txt'), 'w')\n",
    "for i in range(len(names)):\n",
    "    if i == args.s:\n",
    "        continue\n",
    "    args.t = i\n",
    "    args.name = names[args.s][0].upper() + names[args.t][0].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4dfcbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/'\n",
    "args.s_dset_path = folder + args.dset + '/' + names[args.s] + '_list.txt'\n",
    "args.test_dset_path = folder + args.dset + '/' + names[args.t] + '_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c45eb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dset == 'office-home':\n",
    "    if args.da == 'pda':\n",
    "        args.class_num = 65\n",
    "        args.src_classes = [i for i in range(65)]\n",
    "        args.tar_classes = [i for i in range(25)]\n",
    "    if args.da == 'oda':\n",
    "        args.class_num = 25\n",
    "        args.src_classes = [i for i in range(25)]\n",
    "        args.tar_classes = [i for i in range(65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5854cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: val, Task: WD, Accuracy = 97.79%\n"
     ]
    }
   ],
   "source": [
    "test_target(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe1bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (test)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
